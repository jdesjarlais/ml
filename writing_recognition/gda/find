#!/usr/bin/env python3

# Estimates the digit in an image from the mnist data set using guassian discriminate analysis

import numpy as np
import torch
import time
import math

from torchvision import transforms, utils
from torch.utils.data import Dataset, DataLoader


######### SETTINGS #########
should_train = True
learning_rate = 0.07
epochs = 200
training_batch_size = 1
stop_point = 70000
assumes_equal_class_distribution = False

training_labels_file = "/Users/adesjarlais/devel/data/mnist/train-labels-idx1-ubyte"
training_images_file = "/Users/adesjarlais/devel/data/mnist/train-images-idx3-ubyte"

test_labels_file = "/Users/adesjarlais/devel/data/mnist/t10k-labels-idx1-ubyte"
test_images_file = "/Users/adesjarlais/devel/data/mnist/t10k-images-idx3-ubyte"

model_save_file = "/Users/adesjarlais/devel/data/models/writing_recognition/soft_max_classifier/model.pt"
save_model = True
use_saved_model = True
############################



# Transforms

class Normalize(object):
    """Normalize a tensor to a min/max range."""

    __input_range = 1.0
    __output_range = 1.0

    def __init__(self, input_min, input_max, output_min=0.0, output_max=1.0):
        self.input_min = input_min
        self.__input_range = input_max - input_min

        self.output_min = output_min
        self.__output_range = output_max - output_min

    def __call__(self, sample):
        assert(type(sample) is torch.Tensor)

        normalized_sample = (sample - self.input_min)/self.__input_range
        return (normalized_sample * self.__output_range) + self.output_min

class ToTensor(object):
    """Convert ndarrays in sample to Tensors."""

    def __call__(self, sample):
        tensor = None
        if type(sample) is np.ndarray:
            tensor = torch.from_numpy(sample)
        else:
            tensor = torch.Tensor([sample])
        return tensor


# Datasets

class MNISTDataset(Dataset):

    images_file_path = None
    labels_file_path = None

    image_size = None

    __has_been_loaded = False

    __len = None
    __images = None
    __labels = None

    def __init__(self, images_file_path, labels_file_path, input_transform=None, label_transform=None):
        self.images_file_path = images_file_path
        self.labels_file_path = labels_file_path

        self.input_transform = input_transform
        self.label_transform = label_transform

    def __len__(self):
        self.__load_data_set_if_needed()

        return self.__len

    def __getitem__(self, idx):
        self.__load_data_set_if_needed()

        image = self.__images[idx]
        if self.input_transform is not None:
            image = self.input_transform(image)

        label = self.__labels[idx]
        if self.label_transform is not None:
            label = self.label_transform(label)

        return image, label

    def __load_data_set_if_needed(self):
        if not self.__has_been_loaded:
            self.__load_data_set()

    def __load_data_set(self):
        assert(not self.__has_been_loaded)

        self.__has_been_loaded = True

        with open(self.images_file_path, "r") as images_file:
            header = np.fromfile(images_file, dtype=np.dtype('>i4'), count=4)

            magic_number = header[0]
            item_count = header[1]
            num_rows = header[2]
            num_columns = header[3]
            pixels_per_image = num_rows * num_columns
            images_bytes = np.fromfile(images_file, dtype=np.ubyte, count=-1)

            images_file.close()

            assert(magic_number == 2051)
            assert(num_rows == 28)
            assert(num_columns == 28)
            assert(images_bytes.size == item_count * num_rows * num_columns)

            images = np.reshape(images_bytes, (item_count, -1))

            # TODO: is there a way to apply Transforms to a list or inputs

            self.image_size = num_rows * num_columns
            self.__images = images

        with open(self.labels_file_path, "r") as labels_file:
            header = np.fromfile(labels_file, dtype=np.dtype('>i4'), count=2)

            magic_number = header[0]
            item_count = header[1]
            labels = np.fromfile(labels_file, dtype=np.ubyte, count=-1)

            labels_file.close()

            assert(magic_number == 2049)
            assert(labels.size == item_count)

            self.__labels = labels

        assert(self.__images.shape[0] == self.__labels.shape[0])

        self.__len = self.__images.shape[0]


# Functions

def compute_model_accuracy(model, dataset):
    accuracy = 0
    with torch.no_grad():
        model.eval()

        inputs, labels = dataset[:]
        inputs = inputs.to(device)
        labels = labels.to(device)

        outputs = model(inputs)

        predicted_value = torch.argmax(outputs, dim=1)
        actual_value = torch.argmax(labels, dim=1)
        correct_values = torch.eq(predicted_value, actual_value)
        total_correct = torch.sum(correct_values).item()

        accuracy = total_correct/inputs.shape[0]

    return accuracy

def compute_model_loss(model, loss_function, inputs, labels):
    inputs = inputs.to(device)
    labels = labels.to(device).float()

    outputs = model(inputs)
    losses = loss_function(outputs, labels)

    return losses



# Training

device = "mps" if torch.backends.mps.is_available() else "cpu"
print(f"Using device: {device}")


input_transform = transforms.Compose([
    ToTensor(),
    Normalize(input_min=0, input_max=255, output_min=0.0, output_max=1.0)
])

mnist_train_dataset = MNISTDataset(images_file_path=training_images_file,
                                   labels_file_path=training_labels_file,
                                   input_transform=input_transform,
                                   label_transform=None)
mnist_test_dataset = MNISTDataset(images_file_path=test_images_file,
                                  labels_file_path=test_labels_file,
                                  input_transform=input_transform,
                                  label_transform=None)

mnist_train_dataloader = DataLoader(mnist_train_dataset, batch_size=training_batch_size, shuffle=True, num_workers=0)
mnist_test_dataloader = DataLoader(mnist_test_dataset, shuffle=True, num_workers=0)

# TODO: remove
n = 784
covariance = torch.zeros((n, n), device=device)
mean = torch.zeros((10, n), device=device)
class_counts = torch.zeros(10, device=device)



start_time = time.time()

# Calculate mean
for i, (inputs, labels) in enumerate(mnist_train_dataloader):
    assert(inputs.shape[0] == 1)

    inputs = inputs.to(device)

    input = inputs.reshape((-1,))
    digit = labels.item()

    mean[digit] = mean[digit] + input
    class_counts[digit] += 1

    print(f"Mean {i}")
    if i + 1 >= stop_point:
        break

mean = mean / class_counts.unsqueeze(1)


# Calculate covariance
for i, (inputs, labels) in enumerate(mnist_train_dataloader):
    assert(inputs.shape[0] == 1)

    inputs = inputs.to(device)
    input = inputs.reshape((-1,))

    digit = labels.item()
    digit_mean = mean[digit]

    delta = torch.sub(input, digit_mean)
    delta = delta.reshape((-1, 1)).float()
    delta_transpose = torch.transpose(delta, 0, 1)

    cov_contribution = torch.matmul(delta, delta_transpose)
    covariance += cov_contribution
 
    print(f"Covariance {i}")
    if i + 1 >= stop_point:
        break


total_count = torch.sum(class_counts).item()
covariance = covariance / total_count
# TODO: try assuming all classes are equal?
class_probabilities = class_counts / total_count

covariance = covariance.to("cpu")
covariance_inv = torch.linalg.pinv(covariance).to(device)

covariance = covariance.to(device)
covariance_inv = covariance_inv.to(device)


correct_count = 0
total_count = 0
for i, (inputs, labels) in enumerate(mnist_test_dataloader):
    assert(inputs.shape[0] == 1)

    inputs = inputs.to(device)
    input = inputs.reshape((-1,))

    digit_class_probabilities = torch.zeros(10, device=device)
    arbitrary_constant_to_bring_into_float32_range1 = 1.0e152

    digit = labels.item()
    for digit_class in range(9):
        digit_mean = mean[digit_class]
        
        delta = torch.sub(input, digit_mean)
        delta = delta.reshape((-1, 1)).float()
        delta_transpose = torch.transpose(delta, 0, 1)

        exp_input = -0.5 * delta_transpose
        
        exp_input = torch.matmul(exp_input, covariance_inv)
        exp_input = torch.matmul(exp_input, delta)
        exp_output = math.exp(exp_input.item())

        output = exp_output * arbitrary_constant_to_bring_into_float32_range1
        class_probability = class_probabilities[digit_class].item()

        final = output * class_probability
        digit_class_probabilities[digit_class] = final


    if assumes_equal_class_distribution:
        digit_class_estimation = digit_class_probabilities
    else:
        digit_class_estimation = digit_class_probabilities * class_probabilities

    estimated_digit = torch.argmax(digit_class_estimation)

    print(f"Label: {digit} Output: {estimated_digit}")


    if digit == estimated_digit:
        correct_count += 1
    total_count += 1


       
# Determine likely hood that the sample came from each distribution

print("Training complete.")
print("")

# Print losses one last time
print("FINAL RESULTS:")
accuracy = correct_count/total_count
print(f"Accuracy: {accuracy:0.4f}")


end_time = time.time()
print("Total execution time: {:.2f}".format(end_time - start_time))
