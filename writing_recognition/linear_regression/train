#!/usr/bin/env python3


# Trains a linear regression model using gradient descent on the mnist data set.

import numpy as np
import time



######### SETTINGS #########
training_example_count = 60000
test_example_count = 10000
alpha = 0.000003
gradient_descent_iterations = 1000
training_batch_size = 1000
test_batch_size = 100

training_labels_file = "/Users/adesjarlais/devel/data/mnist/train-labels-idx1-ubyte"
training_images_file = "/Users/adesjarlais/devel/data/mnist/train-images-idx3-ubyte"

test_labels_file = "/Users/adesjarlais/devel/data/mnist/t10k-labels-idx1-ubyte"
test_images_file = "/Users/adesjarlais/devel/data/mnist/t10k-images-idx3-ubyte"
############################



def get_labels_from_file(file):

    with open(file, "r") as f1:
        header = np.fromfile(f1, dtype=np.dtype('>i4'), count=2)

        magic_number = header[0]
        item_count = header[1]
        labels = np.fromfile(f1, dtype=np.ubyte, count=-1)

        f1.close()

        assert(magic_number == 2049)
        assert(labels.size == item_count)

        return labels

def get_images_from_file(file):
    with open(file, "r") as f1:
        header = np.fromfile(f1, dtype=np.dtype('>i4'), count=4)

        magic_number = header[0]
        item_count = header[1]
        num_rows = header[2]
        num_columns = header[3]
        pixels_per_image = num_rows * num_columns
        images_bytes = np.fromfile(f1, dtype=np.ubyte, count=-1)

        f1.close()

        assert(magic_number == 2051)
        assert(num_rows == 28)
        assert(num_columns == 28)
        assert(images_bytes.size == item_count * num_rows * num_columns)

        images = np.reshape(images_bytes, (item_count, num_rows * num_columns))

        return images


def inference(input, model_params):
    output_array = np.multiply(input, model_params)
    output = np.sum(output_array)

    return output

def conform_training_image(image):
    model_input = image * 1.0/255.0
    model_input = np.insert(model_input, 0, 1)

    return model_input

def get_conformed_images_from_file(file):
    images = get_images_from_file(file)

    model_inputs = np.zeros((images.shape[0], images.shape[1] + 1))
    for image_index in range(images.shape[0]):
        model_inputs[image_index] = conform_training_image(images[image_index])

    return model_inputs

def batch_inference(model_params, input, labels):
    input_count = input.shape[0]

    model_outputs = np.multiply(input, model_params)
    model_outputs = np.sum(model_outputs, axis=1)

    model_losses = np.subtract(model_outputs, labels)
    model_loss = np.mean(model_losses)

    model_loss_mses = model_losses ** 2
    model_loss_mse = np.mean(model_loss_mses)

    classified_outputs = np.clip(model_outputs, 0, 9)
    classified_outputs = np.round_(classified_outputs, decimals=0)

    correct_inferences = classified_outputs == labels
    total_correct = np.sum(correct_inferences)
    accuracy = total_correct/input_count

    return (model_losses, model_loss, model_loss_mse, accuracy)

def validate_model(model_params, training_inputs, training_labels, test_inputs, test_labels):
    training_losses, avg_training_loss, avg_training_mse, avg_training_accuracy = batch_inference(model_params, training_inputs, training_labels)
    test_losses, avg_test_loss, avg_test_mse, avg_test_accuracy = batch_inference(model_params, test_inputs, test_labels)

    print(f"TRAINING:\tLoss: {avg_training_mse:.2f}\t\t\tAccuracy: {avg_training_accuracy:.2f}")
    print(f"TEST:\t\tLoss: {avg_test_mse:.2f}\t\t\tAccuracy: {avg_test_accuracy:.2f}")
    print("")

    return training_losses



# Pull in training and test inputs and labels
training_labels = get_labels_from_file(training_labels_file)[:training_example_count]
training_images = get_conformed_images_from_file(training_images_file)[:training_example_count]
training_input_size = training_images.shape[1]

test_labels = get_labels_from_file(test_labels_file)[:test_example_count]
test_images = get_conformed_images_from_file(test_images_file)[:test_example_count]
test_input_size = test_images.shape[1]


# Initialize global variables for the model training
model_params = np.zeros(training_input_size)
cached_inference_losses = np.zeros(training_batch_size)
training_index_set = np.arange(training_example_count)
test_index_set = np.arange(test_example_count)


start_time = time.time()
for gd_iteration in range(gradient_descent_iterations):

    # Create randomized batches of size training_batch_size from the training data/labels
    training_batch_indices = np.random.choice(training_index_set, size=training_batch_size, replace=False)
    batch_training_inputs = np.take(training_images, training_batch_indices, axis=0)
    batch_training_labels = np.take(training_labels, training_batch_indices, axis=0)

    # Create randomized batches of size test_batch_size from the test data/labels
    test_batch_indices = np.random.choice(test_index_set, size=test_batch_size, replace=False)
    batch_test_inputs = np.take(test_images, test_batch_indices, axis=0)
    batch_test_labels = np.take(test_labels, test_batch_indices, axis=0)

    # Run the model across the training and test batch, caching the model loss values (later to be used for the gradient descent).
    cached_inference_losses = validate_model(model_params, batch_training_inputs, batch_training_labels, batch_test_inputs, batch_test_labels)

    # Perform gradient descent
    for model_param_index in range(model_params.shape[0]):
        model_param_cost_derivative = 0

        for training_example_index in range(batch_training_inputs.shape[0]):
            model_input = batch_training_inputs[training_example_index]
            model_input_param = model_input[model_param_index]
            model_param_cost_derivative += cached_inference_losses[training_example_index] * model_input_param

        model_params[model_param_index] = model_params[model_param_index] - alpha * model_param_cost_derivative

# Reprint losses on last time
print("Training Complete.")
print("FINAL RESULTS:")
validate_model(model_params, training_images, training_labels, test_images, test_labels)

end_time = time.time()
print("Total execution time: {:.2f}".format(end_time - start_time))
